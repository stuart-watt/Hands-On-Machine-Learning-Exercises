{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "\n",
    "In this notebook, I practise the techniques for building a classification model. I will use the Titanic dataset to try and predict whether or not a passenger survives the disaster based on some features.\n",
    "\n",
    "This dataset acn be found at https://www.kaggle.com/c/titanic\n",
    "\n",
    "To begin with lets import the training and test sets and have a look at the training data. These are already split for us so we don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/titanic/train.csv\")\n",
    "test = pd.read_csv(\"datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 11 features and 1 class (survived). There are 891 instances. All the feature columns are full except for Age, Cabin and Embarked. Since the Age and Embarked attributes are almost full, we will try to fill them in using some of the other features (try to find some correlations or use the mean values) Since the cabin feature is only about 25% full, we will drop this feature for now.\n",
    "\n",
    "Now lets separate the training data into the features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "5            6       3                                   Moran, Mr. James   \n",
       "6            7       1                            McCarthy, Mr. Timothy J   \n",
       "7            8       3                     Palsson, Master. Gosta Leonard   \n",
       "8            9       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9           10       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "5    male   NaN      0      0            330877   8.4583   NaN        Q  \n",
       "6    male  54.0      0      0             17463  51.8625   E46        S  \n",
       "7    male   2.0      3      1            349909  21.0750   NaN        S  \n",
       "8  female  27.0      0      2            347742  11.1333   NaN        S  \n",
       "9  female  14.0      1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories for sex and Embarked will need to be encoded, using binary encoding for Sex (0 for male, 1 for female) and one-hot-encoding for Embarked. Also, passenger ID is not an attribute we want to train the data on, so we will drop this attribute as well as cabin. Since the Ticket number is also seeminly random and unstructured, we will drop this column also.\n",
    "\n",
    "So the final dataset has the attributes:\n",
    "\n",
    "PClass, Sex, Age, SibSp, Parch, Fare, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced = X_train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "X_train_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a class to select the attributes we want so we can put it into a pipeline for the test set. We will also drop any instances with NaN values in the categorical data columns (Sex and Embarked):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    889 non-null int64\n",
      "Survived       889 non-null int64\n",
      "Pclass         889 non-null int64\n",
      "Name           889 non-null object\n",
      "Sex            889 non-null object\n",
      "Age            712 non-null float64\n",
      "SibSp          889 non-null int64\n",
      "Parch          889 non-null int64\n",
      "Ticket         889 non-null object\n",
      "Fare           889 non-null float64\n",
      "Cabin          202 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.3+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "X_attr = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "y_attr = ['Survived']\n",
    "\n",
    "class AttributeSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attributes):\n",
    "        self.attributes = attributes\n",
    "        \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.attributes]\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return X[self.attributes]\n",
    "    \n",
    "\n",
    "train.dropna(subset=['Sex', 'Embarked'], inplace=True)\n",
    "train.info()\n",
    "\n",
    "attrib_select_X = AttributeSelector(X_attr)\n",
    "attrib_select_y = AttributeSelector(y_attr)\n",
    "\n",
    "X_train = attrib_select_X.transform(train)\n",
    "y_train = attrib_select_y.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      "Pclass      889 non-null int64\n",
      "Sex         889 non-null object\n",
      "Age         712 non-null float64\n",
      "SibSp       889 non-null int64\n",
      "Parch       889 non-null int64\n",
      "Fare        889 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to deal with missing values. For the age, we will simply use the mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "num_attributes = X_train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "imputer = Imputer(strategy=\"mean\")\n",
    "\n",
    "num_attributes = imputer.fit_transform(num_attributes)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_attributes = scaler.fit_transform(num_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sex = X_train['Sex'].values\n",
    "sex_encoder = LabelEncoder()\n",
    "sex_encoded = sex_encoder.fit_transform(sex)\n",
    "\n",
    "embarked = X_train['Embarked'].values\n",
    "embarked_encoder = LabelEncoder()\n",
    "embarked_encoded = embarked_encoder.fit_transform(embarked)\n",
    "\n",
    "onehot = OneHotEncoder(sparse=False)\n",
    "embarked_encoded = onehot.fit_transform(embarked_encoded.reshape(-1, 1))[:, :-1]\n",
    "# I dropped one of the embarked columns since one of the classes is a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82520863, -0.58961986,  0.43135024, -0.47432585, -0.50023975,\n",
       "        1.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean = np.c_[num_attributes, sex_encoded, embarked_encoded]\n",
    "X_train_clean[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 8) (889, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_clean.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now the trainnig data is all prepared. We can now start to choose our models. This is a binary classification task. The models I will investigate are:\n",
    "\n",
    "1. SGDClassifier\n",
    "2. RandomForestClassifier\n",
    "\n",
    "I will use the precision, reacll and accuracy to evaluate each model and to tune the hyperparameters. \n",
    "\n",
    "To begin with, I will combine all the data prep stages into a single pipeline so preparing the test set will be easy.\n",
    "\n",
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "num_attr = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "sex_attr = ['Sex']\n",
    "emb_attr = ['Embarked']\n",
    "\n",
    "# Create a transformer to drop instances of NaN\n",
    "class DropInstance(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def transform(self, X, attributes, y=None):\n",
    "        return X.dropna(subset=attributes)\n",
    "    \n",
    "    def fit_transform(self, X, attributes, y=None):\n",
    "        return X.dropna(subset=attributes)\n",
    "    \n",
    "\n",
    "# Modified label encoder to feed into onehot encoder\n",
    "class ModifiedLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(y.values.ravel()).reshape(-1, 1)\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(y.values.ravel()).reshape(-1, 1)\n",
    "    \n",
    "\n",
    "# Modified onehot encoder to delete dummy variable\n",
    "class ModifiedOneHot(OneHotEncoder):\n",
    "    \n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(y)[:, :-1]\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(y)[:, :-1]\n",
    "\n",
    "    \n",
    "num_pipeline = Pipeline([\n",
    "    ('Selector', AttributeSelector(num_attr)),\n",
    "    ('imputer', Imputer(strategy=\"mean\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "sex_pipeline = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "emb_pipeline = Pipeline([\n",
    "    ('Selector', AttributeSelector(emb_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "    ('onehotencoder', ModifiedOneHot(sparse=False)),\n",
    "])\n",
    "\n",
    "full_pipeline_X = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('sex_pipeline', sex_pipeline),\n",
    "    ('emb_piepline', emb_pipeline),\n",
    "])\n",
    "\n",
    "titanic_prepared = full_pipeline_X.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=5, tol=None)\n",
    "\n",
    "scores = cross_val_score(sgd_clf, titanic_prepared, y_train.values.ravel(), cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69360269, 0.71959459, 0.67567568])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, these accuracy scores are quite low. Lets look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410, 139],\n",
       "       [112, 228]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = cross_val_predict(sgd_clf, titanic_prepared, y_train.values.ravel(), cv=3)\n",
    "\n",
    "sgd_conf = confusion_matrix(y_train, y_pred)\n",
    "sgd_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also look at the precision and recall scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6212534059945504 \n",
      "Recall:  0.6705882352941176 \n",
      "F1 Score:  0.6449787835926449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Precision: ',\n",
    "      precision_score(y_train, y_pred),\n",
    "      '\\nRecall: ',\n",
    "      recall_score(y_train, y_pred),\n",
    "      '\\nF1 Score: ',\n",
    "      f1_score(y_train, y_pred)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are similarly bad. This indicates that the linear classifier is perhaps not suited to this data set. Lets use a random forest instead.\n",
    "\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76430976, 0.78040541, 0.78378378])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "scores_forest = cross_val_score(forest_clf, titanic_prepared, y_train.values.ravel(), cv=3, scoring='accuracy')\n",
    "scores_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7639344262295082 \n",
      "Recall:  0.6852941176470588 \n",
      "F1 Score:  0.7224806201550387\n"
     ]
    }
   ],
   "source": [
    "y_pred_forest = cross_val_predict(forest_clf, titanic_prepared, y_train.values.ravel(), cv=3)\n",
    "\n",
    "print('Precision: ',\n",
    "      precision_score(y_train, y_pred_forest),\n",
    "      '\\nRecall: ',\n",
    "      recall_score(y_train, y_pred_forest),\n",
    "      '\\nF1 Score: ',\n",
    "      f1_score(y_train, y_pred_forest)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[477,  72],\n",
       "       [107, 233]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_conf = confusion_matrix(y_train, y_pred_forest)\n",
    "forest_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs significantly better than the SGDClassifier. The recall is approximately the same however. THis means that the model got better at recognising non-survivor but not better at recognising survivors. Overall, there is improvement. Lets now try to tune the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40, 50], 'max_features': [2, 4, 6, 8]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = [\n",
    "    {'n_estimators': [10, 20, 30, 40, 50], 'max_features': [2, 4, 6, 8]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835453686414151 {'max_features': 2, 'n_estimators': 10}\n",
      "0.886087950498142 {'max_features': 2, 'n_estimators': 20}\n",
      "0.8917822551223932 {'max_features': 2, 'n_estimators': 30}\n",
      "0.8917822551223932 {'max_features': 2, 'n_estimators': 40}\n",
      "0.8911513514317336 {'max_features': 2, 'n_estimators': 50}\n",
      "0.8898882021767978 {'max_features': 4, 'n_estimators': 10}\n",
      "0.9005684993642872 {'max_features': 4, 'n_estimators': 20}\n",
      "0.894301419053713 {'max_features': 4, 'n_estimators': 30}\n",
      "0.8955583436642398 {'max_features': 4, 'n_estimators': 40}\n",
      "0.8930427253700312 {'max_features': 4, 'n_estimators': 50}\n",
      "0.8968135066399192 {'max_features': 6, 'n_estimators': 10}\n",
      "0.8930427253700312 {'max_features': 6, 'n_estimators': 20}\n",
      "0.894301419053713 {'max_features': 6, 'n_estimators': 30}\n",
      "0.894301419053713 {'max_features': 6, 'n_estimators': 40}\n",
      "0.8930427253700312 {'max_features': 6, 'n_estimators': 50}\n",
      "0.8911513514317336 {'max_features': 8, 'n_estimators': 10}\n",
      "0.890520000766984 {'max_features': 8, 'n_estimators': 20}\n",
      "0.8911513514317336 {'max_features': 8, 'n_estimators': 30}\n",
      "0.8911513514317336 {'max_features': 8, 'n_estimators': 40}\n",
      "0.8961861448935777 {'max_features': 8, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07977406, 0.25918647, 0.04991073, 0.02922823, 0.27318708,\n",
       "       0.27707294, 0.02048972, 0.01115077])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = grid_search.best_estimator_\n",
    "best_forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2770729393478822, 'Sex'),\n",
       " (0.2731870816971812, 'Fare'),\n",
       " (0.2591864705258983, 'Age'),\n",
       " (0.0797740647656712, 'Pclass'),\n",
       " (0.04991072967527385, 'SibSp'),\n",
       " (0.02922822776057791, 'Parch'),\n",
       " (0.020489719214641176, 'Embarked1'),\n",
       " (0.0111507670128742, 'Embarked2')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Embarked1', 'Embarked2']\n",
    "\n",
    "sorted(zip(best_forest.feature_importances_, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important attributes to the model are Sex, Fare (probably related to wealth and cabin location) and Age. Certainly, where they embarked from is not at all important. Because of this I will drop Embarked, Parch and SibSp from the dataset and train the model on this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_num_attr = ['Pclass', 'Age', 'Fare']\n",
    "\n",
    "num_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(important_num_attr)),\n",
    "    ('imputer', Imputer(strategy=\"mean\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "sex_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "new_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline_new),\n",
    "    ('sex_pipeline', sex_pipeline_new),\n",
    "])\n",
    "\n",
    "titanic_prepared_new = new_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [30, 32, 34, 36, 38, 40], 'max_features': [2, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [30, 32, 34, 36, 38, 40], 'max_features': [2, 4]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared_new, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8936722938129552 {'max_features': 2, 'n_estimators': 30}\n",
      "0.8949301020270023 {'max_features': 2, 'n_estimators': 32}\n",
      "0.8968135066399192 {'max_features': 2, 'n_estimators': 34}\n",
      "0.898066915367079 {'max_features': 2, 'n_estimators': 36}\n",
      "0.8955583436642398 {'max_features': 2, 'n_estimators': 38}\n",
      "0.8949301020270023 {'max_features': 2, 'n_estimators': 40}\n",
      "0.8848175728549054 {'max_features': 4, 'n_estimators': 30}\n",
      "0.894301419053713 {'max_features': 4, 'n_estimators': 32}\n",
      "0.8968135066399192 {'max_features': 4, 'n_estimators': 34}\n",
      "0.8911513514317336 {'max_features': 4, 'n_estimators': 36}\n",
      "0.890520000766984 {'max_features': 4, 'n_estimators': 38}\n",
      "0.8911513514317336 {'max_features': 4, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_new = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So removing these features made no difference to the accuracy, as expected. We can now evaluate this model on the test set. First we need to pass the test set through the data prep stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = new_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = forest_new.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if the model predicted correctly, we need to import the results into Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = test['PassengerId']\n",
    "submission['Survived'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('datasets/titanic/submission.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scored 72.7% on the Kaggle leaderboard. This is not bad but could be much better, considering some submissions have 100% accuracy (but maybe these know something I don't). For the purpose of this practise, I think it was helpful.\n",
    "\n",
    "The main thing I have learned from this dataset is how much of a pain missing values can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    340\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6175478065241845\n"
     ]
    }
   ],
   "source": [
    "print(549/(549+340))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even if you just assume everyone dies, the accuracy is still 62%, so we have only improved from this accuracy by about 10%. In fact, by predicting that all men die and all women survive acually gets you a score of 78% so my model is even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame()\n",
    "submission2['PassengerId'] = test['PassengerId']\n",
    "submission2['Survived'] = np.zeros((418,))\n",
    "submission2.to_csv('datasets/titanic/submission2.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (X_test_prepared[:, -1].astype(int) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3 = pd.DataFrame()\n",
    "submission3['PassengerId'] = test['PassengerId']\n",
    "submission3['Survived'] = y\n",
    "submission3.to_csv('datasets/titanic/submission3.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By letting all men die and women survive, my model is actualy better than the random forest model. So we know that Sex is a strong influence on wether someone lives or not. The next most important feature was Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [30, 32, 34, 36, 38, 40]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_num_attr = ['Age']\n",
    "\n",
    "num_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(important_num_attr)),\n",
    "    ('imputer', Imputer(strategy=\"mean\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "sex_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "new_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline_new),\n",
    "    ('sex_pipeline', sex_pipeline_new),\n",
    "])\n",
    "\n",
    "titanic_prepared_new = sex_pipeline_new.fit_transform(X_train)\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [30, 32, 34, 36, 38, 40]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared_new, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = sex_pipeline_new.transform(test)\n",
    "\n",
    "y2 = grid_search.best_estimator_.predict(X_test_new)\n",
    "\n",
    "submission4 = pd.DataFrame()\n",
    "submission4['PassengerId'] = test['PassengerId']\n",
    "submission4['Survived'] = y2\n",
    "submission4.to_csv('datasets/titanic/submission4.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever I add a attribute as well as Sex, the score decreases. I need to perform some feature engineering to come up with a more representable feature.\n",
    "\n",
    "Perhaps we can look at the fare and deduce the social status of the passenger. Or classifiy the passenger as child, adult and senior to make a general age attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d32503fda0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3253ee630>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0, 80, 5)\n",
    "\n",
    "train.loc[train['Survived'] == 0]['Age'].hist(bins=bins)\n",
    "train.loc[train['Survived'] == 1]['Age'].hist(alpha=0.4, bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this histogram shows is the number of passengers in different age groups that survived (orange) and died (blue). What we see is that for under 10s, the majority survived. ie, for infants. However, for the others, the majority died. Especially in the middle section (15-40). I will now cetegorise the ages into these 3 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "infants = (train['Age'] < 10).astype(int)\n",
    "adults = (train['Age'] <= 40).astype(int)\n",
    "seniors = (train['Age'] <= 100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cat = infants + adults + seniors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age Cat'] = age_cat\n",
    "y_train = train['Survived'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_num_attr = ['Age Cat']\n",
    "\n",
    "num_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(important_num_attr)),\n",
    "])\n",
    "\n",
    "sex_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "new_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline_new),\n",
    "    ('sex_pipeline', sex_pipeline_new),\n",
    "])\n",
    "\n",
    "titanic_prepared_new = new_pipeline.fit_transform(train)\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [10, 20, 30, 40]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "infants = (test['Age'] < 10).astype(int)\n",
    "adults = (test['Age'] <= 40).astype(int)\n",
    "seniors = (test['Age'] <= 100).astype(int)\n",
    "test['Age Cat'] = infants + adults + seniors\n",
    "\n",
    "X_test_new = new_pipeline.transform(test)\n",
    "\n",
    "y2 = grid_search.best_estimator_.predict(X_test_new)\n",
    "\n",
    "submission5 = pd.DataFrame()\n",
    "submission5['PassengerId'] = test['PassengerId']\n",
    "submission5['Survived'] = y2\n",
    "submission5.to_csv('datasets/titanic/submission5.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this slightly improved the model! Lets do the same thing for Fare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3268e9eb8>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0, 300, 10)\n",
    "\n",
    "train.loc[train['Survived'] == 0]['Fare'].hist(bins=bins)\n",
    "train.loc[train['Survived'] == 1]['Fare'].hist(alpha=0.4, bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can also see that the lower fare people tended to die, while the mojority of high fare passengers survived. Lets make categories for these ones aswell. I will have two categories for this, rich and poor (<$50 fare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d326cc4f60>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0, 4, 0.5)\n",
    "\n",
    "train.loc[train['Survived'] == 0]['Pclass'].hist(bins=bins)\n",
    "train.loc[train['Survived'] == 1]['Pclass'].hist(alpha=0.4, bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also see that Pclass gives a good indication of death or not. THe 3rd class passengers are extremely likely to die, while 1st class a more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare cat'] = (train['Fare'] < 50).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_num_attr = ['Age Cat', 'Fare cat', 'Pclass']\n",
    "\n",
    "num_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(important_num_attr)),\n",
    "])\n",
    "\n",
    "sex_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "new_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline_new),\n",
    "    ('sex_pipeline', sex_pipeline_new),\n",
    "])\n",
    "\n",
    "titanic_prepared_new = new_pipeline.fit_transform(train)\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [10, 20, 30, 40]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare cat'] = (test['Fare'] < 50).astype(int)\n",
    "\n",
    "X_test_new = new_pipeline.transform(test)\n",
    "\n",
    "y2 = grid_search.best_estimator_.predict(X_test_new)\n",
    "\n",
    "submission6 = pd.DataFrame()\n",
    "submission6['PassengerId'] = test['PassengerId']\n",
    "submission6['Survived'] = y2\n",
    "submission6.to_csv('datasets/titanic/submission6.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13483391, 0.06812768, 0.21891971, 0.57811871])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score actually went down! According to the feature importances, the Pclass and Sex are the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_num_attr = ['Pclass']\n",
    "\n",
    "num_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(important_num_attr)),\n",
    "])\n",
    "\n",
    "sex_pipeline_new = Pipeline([\n",
    "    ('Selector', AttributeSelector(sex_attr)),\n",
    "    ('encoder', ModifiedLabelEncoder()),\n",
    "])\n",
    "\n",
    "new_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline_new),\n",
    "    ('sex_pipeline', sex_pipeline_new),\n",
    "])\n",
    "\n",
    "titanic_prepared_new = new_pipeline.fit_transform(train)\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [10, 20, 30, 40]},\n",
    "]\n",
    "grid_search = GridSearchCV(forest_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(titanic_prepared_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = new_pipeline.transform(test)\n",
    "\n",
    "y2 = grid_search.best_estimator_.predict(X_test_new)\n",
    "\n",
    "submission6 = pd.DataFrame()\n",
    "submission6['PassengerId'] = test['PassengerId']\n",
    "submission6['Survived'] = y2\n",
    "submission6.to_csv('datasets/titanic/submission6.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
